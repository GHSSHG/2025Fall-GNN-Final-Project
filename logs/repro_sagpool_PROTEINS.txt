Training loss:0.6888132691383362
Training loss:0.6879494190216064
Training loss:0.6880452036857605
Training loss:0.686318576335907
Validation loss:0.6879960481110994	accuracy:0.5765765765765766
Model saved at epoch0
Training loss:0.6900677680969238
Training loss:0.687871515750885
Training loss:0.6823740005493164
Training loss:0.6858758330345154
Validation loss:0.6868442844700169	accuracy:0.5765765765765766
Model saved at epoch1
Training loss:0.6895207166671753
Training loss:0.6813044548034668
Training loss:0.6877433061599731
Training loss:0.6755356192588806
Validation loss:0.6857452392578125	accuracy:0.5765765765765766
Model saved at epoch2
Training loss:0.6827378869056702
Training loss:0.6861556768417358
Training loss:0.6809065341949463
Training loss:0.6847766041755676
Validation loss:0.6846771240234375	accuracy:0.5765765765765766
Model saved at epoch3
Training loss:0.6849323511123657
Training loss:0.6818032264709473
Training loss:0.6838878393173218
Training loss:0.6797022223472595
Validation loss:0.6836753364081856	accuracy:0.5765765765765766
Model saved at epoch4
Training loss:0.687224805355072
Training loss:0.6816331148147583
Training loss:0.6739951372146606
Training loss:0.6831687092781067
Validation loss:0.6827069531689893	accuracy:0.5765765765765766
Model saved at epoch5
Training loss:0.6870598793029785
Training loss:0.6791903972625732
Training loss:0.6767673492431641
Training loss:0.6762111186981201
Validation loss:0.6816876385663007	accuracy:0.5765765765765766
Model saved at epoch6
Training loss:0.6771459579467773
Training loss:0.681260347366333
Training loss:0.6808579564094543
Training loss:0.673732340335846
Validation loss:0.6805363560582066	accuracy:0.5765765765765766
Model saved at epoch7
Training loss:0.6723017692565918
Training loss:0.6785764694213867
Training loss:0.6869770884513855
Training loss:0.6645610928535461
Validation loss:0.6790075903540259	accuracy:0.5765765765765766
Model saved at epoch8
Training loss:0.677749514579773
Training loss:0.6662654280662537
Training loss:0.6807146668434143
Training loss:0.6777436137199402
Validation loss:0.6771488361530476	accuracy:0.5765765765765766
Model saved at epoch9
Training loss:0.6802273392677307
Training loss:0.6700537800788879
Training loss:0.6633417010307312
Training loss:0.6861438155174255
Validation loss:0.6751106880806588	accuracy:0.5765765765765766
Model saved at epoch10
Training loss:0.6801090240478516
Training loss:0.6718139052391052
Training loss:0.6698238849639893
Training loss:0.6632131338119507
Validation loss:0.6724742167704815	accuracy:0.5765765765765766
Model saved at epoch11
Training loss:0.6541852951049805
Training loss:0.6807677745819092
Training loss:0.6654081344604492
Training loss:0.6738595366477966
Validation loss:0.6685499586500563	accuracy:0.5765765765765766
Model saved at epoch12
Training loss:0.651840329170227
Training loss:0.6610671281814575
Training loss:0.6760109066963196
Training loss:0.6673126220703125
Validation loss:0.6636319547086149	accuracy:0.5765765765765766
Model saved at epoch13
Training loss:0.6595039367675781
Training loss:0.6608924269676208
Training loss:0.6663190126419067
Training loss:0.6524071097373962
Validation loss:0.6565374425939612	accuracy:0.5765765765765766
Model saved at epoch14
Training loss:0.6603330373764038
Training loss:0.6479395031929016
Training loss:0.640411376953125
Training loss:0.6640416979789734
Validation loss:0.6471839423652168	accuracy:0.5765765765765766
Model saved at epoch15
Training loss:0.6464364528656006
Training loss:0.6546190977096558
Training loss:0.6331170201301575
Training loss:0.6466559171676636
Validation loss:0.6366433495873803	accuracy:0.5765765765765766
Model saved at epoch16
Training loss:0.6461209654808044
Training loss:0.6443569660186768
Training loss:0.6191281080245972
Training loss:0.6327658295631409
Validation loss:0.6230281795467343	accuracy:0.5855855855855856
Model saved at epoch17
Training loss:0.6202311515808105
Training loss:0.6282914876937866
Training loss:0.6384379863739014
Training loss:0.6284958720207214
Validation loss:0.6085935025601774	accuracy:0.6126126126126126
Model saved at epoch18
Training loss:0.6299552321434021
Training loss:0.5957167148590088
Training loss:0.6156742572784424
Training loss:0.629054605960846
Validation loss:0.5936658704603041	accuracy:0.6486486486486487
Model saved at epoch19
Training loss:0.6168049573898315
Training loss:0.5922322869300842
Training loss:0.6147519946098328
Training loss:0.5663147568702698
Validation loss:0.5776794021194046	accuracy:0.6666666666666666
Model saved at epoch20
Training loss:0.5735460519790649
Training loss:0.6012319326400757
Training loss:0.600673496723175
Training loss:0.5826159715652466
Validation loss:0.5664806881466428	accuracy:0.6846846846846847
Model saved at epoch21
Training loss:0.5849938988685608
Training loss:0.6221597194671631
Training loss:0.5680313110351562
Training loss:0.5748662352561951
Validation loss:0.55760247857721	accuracy:0.7387387387387387
Model saved at epoch22
Training loss:0.5866904854774475
Training loss:0.5845851302146912
Training loss:0.5827599763870239
Training loss:0.5682334899902344
Validation loss:0.539576075098536	accuracy:0.7477477477477478
Model saved at epoch23
Training loss:0.6044416427612305
Training loss:0.5702672600746155
Training loss:0.5681737065315247
Training loss:0.5917356014251709
Validation loss:0.5298580822643933	accuracy:0.7657657657657657
Model saved at epoch24
Training loss:0.5891270637512207
Training loss:0.5665097832679749
Training loss:0.5698868036270142
Training loss:0.5904333591461182
Validation loss:0.5225867194098395	accuracy:0.7927927927927928
Model saved at epoch25
Training loss:0.5662593841552734
Training loss:0.5612532496452332
Training loss:0.5732780694961548
Training loss:0.556678295135498
Validation loss:0.5191663449948972	accuracy:0.7927927927927928
Model saved at epoch26
Training loss:0.5534504652023315
Training loss:0.5806848406791687
Training loss:0.5674493312835693
Training loss:0.5638547539710999
Validation loss:0.5129619632755313	accuracy:0.7927927927927928
Model saved at epoch27
Training loss:0.5803334712982178
Training loss:0.5151949524879456
Training loss:0.6015752553939819
Training loss:0.5191464424133301
Validation loss:0.5055166708456503	accuracy:0.7927927927927928
Model saved at epoch28
Training loss:0.49861353635787964
Training loss:0.6067691445350647
Training loss:0.5437042713165283
Training loss:0.6525834798812866
Validation loss:0.5015397286629891	accuracy:0.7837837837837838
Model saved at epoch29
Training loss:0.5595185160636902
Training loss:0.5563855171203613
Training loss:0.5871201753616333
Training loss:0.587755560874939
Validation loss:0.5016045785165048	accuracy:0.8108108108108109
Training loss:0.5503228902816772
Training loss:0.5738541483879089
Training loss:0.580626368522644
Training loss:0.5343730449676514
Validation loss:0.503698881681975	accuracy:0.8108108108108109
Training loss:0.5709202289581299
Training loss:0.5495232343673706
Training loss:0.5476245284080505
Training loss:0.5804897546768188
Validation loss:0.5040173917203337	accuracy:0.7927927927927928
Training loss:0.5700664520263672
Training loss:0.5600647926330566
Training loss:0.5498576164245605
Training loss:0.5502415895462036
Validation loss:0.49572190293320667	accuracy:0.7927927927927928
Model saved at epoch33
Training loss:0.5965707302093506
Training loss:0.5236250162124634
Training loss:0.5657293200492859
Training loss:0.5352495908737183
Validation loss:0.49460773639850786	accuracy:0.8198198198198198
Model saved at epoch34
Training loss:0.5970824956893921
Training loss:0.535311758518219
Training loss:0.565250039100647
Training loss:0.5387037992477417
Validation loss:0.4952353743819503	accuracy:0.8108108108108109
Training loss:0.5579355955123901
Training loss:0.5567882061004639
Training loss:0.5598299503326416
Training loss:0.5592879056930542
Validation loss:0.49569255382091076	accuracy:0.7747747747747747
Training loss:0.5975897312164307
Training loss:0.5435932874679565
Training loss:0.571518063545227
Training loss:0.5521173477172852
Validation loss:0.49762251570418076	accuracy:0.8108108108108109
Training loss:0.5607258081436157
Training loss:0.6080576777458191
Training loss:0.5220822691917419
Training loss:0.5551701784133911
Validation loss:0.4988985491228533	accuracy:0.7927927927927928
Training loss:0.5424420833587646
Training loss:0.5526650547981262
Training loss:0.5754880905151367
Training loss:0.5087509751319885
Validation loss:0.5081792608037725	accuracy:0.7387387387387387
Test accuarcy:0.7857142857142857
