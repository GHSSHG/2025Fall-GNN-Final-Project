Training loss:0.6885153651237488
Training loss:0.6904273629188538
Training loss:0.6849465370178223
Training loss:0.6888768672943115
Training loss:0.6852933764457703
Training loss:0.6816498041152954
Training loss:0.6842320561408997
Validation loss:0.6841178412909981	accuracy:0.5765765765765766
Model saved at epoch0
Training loss:0.6847753524780273
Training loss:0.6828022003173828
Training loss:0.6884340643882751
Training loss:0.6745553016662598
Training loss:0.6805149912834167
Training loss:0.6771012544631958
Training loss:0.6795567274093628
Validation loss:0.6793511193077844	accuracy:0.5765765765765766
Model saved at epoch1
Training loss:0.6852120161056519
Training loss:0.6768920421600342
Training loss:0.678202748298645
Training loss:0.6784191727638245
Training loss:0.6728211641311646
Training loss:0.6463713645935059
Training loss:0.6882795691490173
Validation loss:0.6738569929793075	accuracy:0.5765765765765766
Model saved at epoch2
Training loss:0.676262378692627
Training loss:0.6784186363220215
Training loss:0.6531515121459961
Training loss:0.6640902757644653
Training loss:0.6713609099388123
Training loss:0.6791263818740845
Training loss:0.636928379535675
Validation loss:0.6662469812341638	accuracy:0.5765765765765766
Model saved at epoch3
Training loss:0.6514080762863159
Training loss:0.6626675128936768
Training loss:0.7075412273406982
Training loss:0.602641224861145
Training loss:0.6637263894081116
Training loss:0.6590920090675354
Training loss:0.6507459282875061
Validation loss:0.6622014776006475	accuracy:0.5765765765765766
Model saved at epoch4
Training loss:0.637346625328064
Training loss:0.6040900945663452
Training loss:0.7338881492614746
Training loss:0.6249666213989258
Training loss:0.6112427115440369
Training loss:0.7031340599060059
Training loss:0.6381604671478271
Validation loss:0.6565301568658503	accuracy:0.5765765765765766
Model saved at epoch5
Training loss:0.7004591226577759
Training loss:0.657213568687439
Training loss:0.6398156881332397
Training loss:0.6314491629600525
Training loss:0.6456552743911743
Training loss:0.6370935440063477
Training loss:0.6056553721427917
Validation loss:0.6471231821421031	accuracy:0.5765765765765766
Model saved at epoch6
Training loss:0.6536062955856323
Training loss:0.6138728857040405
Training loss:0.6252473592758179
Training loss:0.6632637977600098
Training loss:0.6216263175010681
Training loss:0.6705074310302734
Training loss:0.6321336030960083
Validation loss:0.6414095904376056	accuracy:0.6216216216216216
Model saved at epoch7
Training loss:0.6203027963638306
Training loss:0.6114801168441772
Training loss:0.6204935312271118
Training loss:0.6225872039794922
Training loss:0.6814360022544861
Training loss:0.6167734861373901
Training loss:0.6493068337440491
Validation loss:0.6288250072582348	accuracy:0.6576576576576577
Model saved at epoch8
Training loss:0.6067641973495483
Training loss:0.6457690000534058
Training loss:0.6021134257316589
Training loss:0.6351951360702515
Training loss:0.6642957925796509
Training loss:0.6282433271408081
Training loss:0.5967938899993896
Validation loss:0.6154263470623944	accuracy:0.6486486486486487
Model saved at epoch9
Training loss:0.6144287586212158
Training loss:0.5559085011482239
Training loss:0.6010802984237671
Training loss:0.6163551807403564
Training loss:0.6650558114051819
Training loss:0.6305418610572815
Training loss:0.6527460813522339
Validation loss:0.5993077733495213	accuracy:0.6576576576576577
Model saved at epoch10
Training loss:0.6364012956619263
Training loss:0.6156625747680664
Training loss:0.5785897970199585
Training loss:0.6111220717430115
Training loss:0.6138948202133179
Training loss:0.5832330584526062
Training loss:0.5918053984642029
Validation loss:0.5778199616853181	accuracy:0.6666666666666666
Model saved at epoch11
Training loss:0.560723066329956
Training loss:0.613517701625824
Training loss:0.6163785457611084
Training loss:0.5759766697883606
Training loss:0.543857216835022
Training loss:0.5972282886505127
Training loss:0.6344505548477173
Validation loss:0.5602445516500387	accuracy:0.7207207207207207
Model saved at epoch12
Training loss:0.5414903163909912
Training loss:0.6175202131271362
Training loss:0.5712727308273315
Training loss:0.5506356954574585
Training loss:0.5570030212402344
Training loss:0.6186609864234924
Training loss:0.5847808122634888
Validation loss:0.537920771418391	accuracy:0.7387387387387387
Model saved at epoch13
Training loss:0.6394845247268677
Training loss:0.4580831527709961
Training loss:0.6416202783584595
Training loss:0.5715248584747314
Training loss:0.5809831619262695
Training loss:0.5018808841705322
Training loss:0.5677939057350159
Validation loss:0.5276073077777484	accuracy:0.7387387387387387
Model saved at epoch14
Training loss:0.589927613735199
Training loss:0.6015352606773376
Training loss:0.5252496600151062
Training loss:0.5843588709831238
Training loss:0.5503252744674683
Training loss:0.5608015060424805
Training loss:0.5049120187759399
Validation loss:0.5209212775702949	accuracy:0.7387387387387387
Model saved at epoch15
Training loss:0.6116437315940857
Training loss:0.49546074867248535
Training loss:0.4926469326019287
Training loss:0.5847324132919312
Training loss:0.5214674472808838
Training loss:0.5670280456542969
Training loss:0.550822913646698
Validation loss:0.5167883795660895	accuracy:0.7297297297297297
Model saved at epoch16
Training loss:0.48864322900772095
Training loss:0.5000405311584473
Training loss:0.5876258015632629
Training loss:0.5904021859169006
Training loss:0.5668206214904785
Training loss:0.5411425828933716
Training loss:0.5571191906929016
Validation loss:0.5108036006893124	accuracy:0.7207207207207207
Model saved at epoch17
Training loss:0.5534859299659729
Training loss:0.569101095199585
Training loss:0.5316666960716248
Training loss:0.5113539695739746
Training loss:0.5216007232666016
Training loss:0.5802841782569885
Training loss:0.5846160650253296
Validation loss:0.5094995584573832	accuracy:0.7297297297297297
Model saved at epoch18
Training loss:0.5244797468185425
Training loss:0.5633553266525269
Training loss:0.5237226486206055
Training loss:0.5141717791557312
Training loss:0.4728843569755554
Training loss:0.5994800925254822
Training loss:0.5653424263000488
Validation loss:0.5147204012484163	accuracy:0.7297297297297297
Training loss:0.5568649768829346
Training loss:0.5472384691238403
Training loss:0.5999674797058105
Training loss:0.5376153588294983
Training loss:0.5689382553100586
Training loss:0.47913774847984314
