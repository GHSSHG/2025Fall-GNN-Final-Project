Training loss:0.6888132691383362
Training loss:0.6879494190216064
Training loss:0.6880452036857605
Training loss:0.686318576335907
Validation loss:0.6879961168443834	accuracy:0.5765765765765766
Model saved at epoch0
Training loss:0.6900677680969238
Training loss:0.687871515750885
Training loss:0.6823740005493164
Training loss:0.6858758330345154
Validation loss:0.6868442844700169	accuracy:0.5765765765765766
Model saved at epoch1
Training loss:0.6895207166671753
Training loss:0.6813044548034668
Training loss:0.6877433061599731
Training loss:0.6755356192588806
Validation loss:0.6857452392578125	accuracy:0.5765765765765766
Model saved at epoch2
Training loss:0.6827379465103149
Training loss:0.6861556768417358
Training loss:0.6809065341949463
Training loss:0.6847765445709229
Validation loss:0.6846770552901534	accuracy:0.5765765765765766
Model saved at epoch3
Training loss:0.6849323511123657
Training loss:0.681803286075592
Training loss:0.6838878393173218
Training loss:0.6797022223472595
Validation loss:0.6836754051414696	accuracy:0.5765765765765766
Model saved at epoch4
Training loss:0.6872248649597168
Training loss:0.6816331744194031
Training loss:0.6739951372146606
Training loss:0.6831687092781067
Validation loss:0.6827068844357053	accuracy:0.5765765765765766
Model saved at epoch5
Training loss:0.6870598793029785
Training loss:0.6791905164718628
Training loss:0.6767673492431641
Training loss:0.6762111186981201
Validation loss:0.6816876385663007	accuracy:0.5765765765765766
Model saved at epoch6
Training loss:0.6771460771560669
Training loss:0.681260347366333
Training loss:0.6808579564094543
Training loss:0.6737324595451355
Validation loss:0.6805363560582066	accuracy:0.5765765765765766
Model saved at epoch7
Training loss:0.6723017692565918
Training loss:0.6785761117935181
Training loss:0.6869771480560303
Training loss:0.6645611524581909
Validation loss:0.67900765908731	accuracy:0.5765765765765766
Model saved at epoch8
Training loss:0.6777493953704834
Training loss:0.6662654876708984
Training loss:0.6807146668434143
Training loss:0.6777347326278687
Validation loss:0.6771488361530476	accuracy:0.5765765765765766
Model saved at epoch9
Training loss:0.6802270412445068
Training loss:0.6700536012649536
Training loss:0.6633442640304565
Training loss:0.6861443519592285
Validation loss:0.6751117878132038	accuracy:0.5765765765765766
Model saved at epoch10
Training loss:0.6801117062568665
Training loss:0.6718264222145081
Training loss:0.6698242425918579
Training loss:0.6631851196289062
Validation loss:0.6724745604369018	accuracy:0.5765765765765766
Model saved at epoch11
Training loss:0.6541669964790344
Training loss:0.6807685494422913
Training loss:0.665398120880127
Training loss:0.6738539934158325
Validation loss:0.6685426729219454	accuracy:0.5765765765765766
Model saved at epoch12
Training loss:0.6518459320068359
Training loss:0.6610703468322754
Training loss:0.6759573221206665
Training loss:0.6673178672790527
Validation loss:0.6635146957259994	accuracy:0.5765765765765766
Model saved at epoch13
Training loss:0.6595594882965088
Training loss:0.6607632637023926
Training loss:0.6663067936897278
Training loss:0.6523807644844055
Validation loss:0.6566043888126407	accuracy:0.5765765765765766
Model saved at epoch14
Training loss:0.66034996509552
Training loss:0.6479017734527588
Training loss:0.6403906345367432
Training loss:0.6640385389328003
Validation loss:0.6477085147892032	accuracy:0.5765765765765766
Model saved at epoch15
Training loss:0.6463695168495178
Training loss:0.6546609401702881
Training loss:0.6330924034118652
Training loss:0.646579384803772
Validation loss:0.6365920058241835	accuracy:0.5765765765765766
Model saved at epoch16
Training loss:0.6461166143417358
Training loss:0.644372820854187
Training loss:0.6191254258155823
Training loss:0.6327434182167053
Validation loss:0.623013195690808	accuracy:0.5855855855855856
Model saved at epoch17
Training loss:0.6202611327171326
Training loss:0.6280997395515442
Training loss:0.6385665535926819
Training loss:0.6284729838371277
Validation loss:0.6085375536669482	accuracy:0.6126126126126126
Model saved at epoch18
Training loss:0.6299273371696472
Training loss:0.5957167148590088
Training loss:0.6156212091445923
Training loss:0.6288926005363464
Validation loss:0.5936282046206363	accuracy:0.6486486486486487
Model saved at epoch19
Training loss:0.6168546676635742
Training loss:0.5922662019729614
Training loss:0.614710807800293
Training loss:0.5664364099502563
Validation loss:0.5776499155405406	accuracy:0.6666666666666666
Model saved at epoch20
Training loss:0.573828935623169
Training loss:0.6010138988494873
Training loss:0.6007771492004395
Training loss:0.5822082161903381
Validation loss:0.5668292002634959	accuracy:0.6846846846846847
Model saved at epoch21
Training loss:0.5852155089378357
Training loss:0.6217536926269531
Training loss:0.5681090354919434
Training loss:0.5758384466171265
Validation loss:0.5566694242460234	accuracy:0.7387387387387387
Model saved at epoch22
Training loss:0.5867647528648376
Training loss:0.5839385986328125
Training loss:0.5821300745010376
Training loss:0.5683937668800354
Validation loss:0.547713752265449	accuracy:0.7477477477477478
Model saved at epoch23
Training loss:0.6051703691482544
Training loss:0.5699321627616882
Training loss:0.5686964988708496
Training loss:0.5915960073471069
Validation loss:0.5294605976826435	accuracy:0.7657657657657657
Model saved at epoch24
Training loss:0.5889691114425659
Training loss:0.569858193397522
Training loss:0.5699930191040039
Training loss:0.5906140804290771
Validation loss:0.5228140891135276	accuracy:0.7927927927927928
Model saved at epoch25
Training loss:0.5657699704170227
Training loss:0.561172366142273
Training loss:0.575332522392273
Training loss:0.5586208701133728
Validation loss:0.5198825458148578	accuracy:0.7927927927927928
Model saved at epoch26
Training loss:0.5549992322921753
Training loss:0.5789601802825928
Training loss:0.5671741366386414
Training loss:0.5629904270172119
Validation loss:0.5128738815720016	accuracy:0.7927927927927928
Model saved at epoch27
Training loss:0.5803040862083435
Training loss:0.5148437023162842
Training loss:0.6043802499771118
Training loss:0.5190960168838501
Validation loss:0.5022713601052224	accuracy:0.7837837837837838
Model saved at epoch28
Training loss:0.49937278032302856
Training loss:0.6077648997306824
Training loss:0.5475680828094482
Training loss:0.658780574798584
Validation loss:0.508827965538781	accuracy:0.7837837837837838
Training loss:0.5574870109558105
Training loss:0.5573692321777344
Training loss:0.5867781639099121
Training loss:0.5895479321479797
Validation loss:0.5032605007962063	accuracy:0.8108108108108109
Training loss:0.5518955588340759
Training loss:0.5751919746398926
Training loss:0.5808085799217224
Training loss:0.5350016355514526
Validation loss:0.5118424011780335	accuracy:0.8018018018018018
Training loss:0.5705950260162354
Training loss:0.5502578020095825
Training loss:0.5479334592819214
Training loss:0.5811408758163452
Validation loss:0.5152232883212803	accuracy:0.7837837837837838
Training loss:0.568337082862854
Training loss:0.5603904128074646
Training loss:0.5498831272125244
Training loss:0.5510817766189575
Validation loss:0.5031656488641962	accuracy:0.7927927927927928
Training loss:0.5967182517051697
Training loss:0.5225662589073181
Training loss:0.5655227899551392
Training loss:0.5359313488006592
Validation loss:0.4950934745169975	accuracy:0.8108108108108109
Model saved at epoch34
Training loss:0.59715735912323
Training loss:0.5346070528030396
Training loss:0.5658600926399231
Training loss:0.5407451391220093
Validation loss:0.49526950045748874	accuracy:0.8108108108108109
Training loss:0.5585384964942932
Training loss:0.5570900440216064
Training loss:0.5601266622543335
Training loss:0.5579935908317566
Validation loss:0.4955271815394496	accuracy:0.7747747747747747
Training loss:0.597371518611908
Training loss:0.544304609298706
Training loss:0.57028728723526
Training loss:0.5517996549606323
Validation loss:0.49952281917537655	accuracy:0.7927927927927928
Training loss:0.5606560111045837
Training loss:0.6075115203857422
Training loss:0.5226689577102661
Training loss:0.5559750199317932
Validation loss:0.4984348743885487	accuracy:0.7927927927927928
Training loss:0.5421441793441772
Training loss:0.5539883375167847
Training loss:0.5768106579780579
Training loss:0.5093105435371399
Validation loss:0.500840882997255	accuracy:0.7387387387387387
Traceback (most recent call last):
  File "/Users/a1234/Downloads/GNN/third_party/SAGPool/main.py", line 102, in <module>
    test_acc,test_loss = test(model,test_loader)
                         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/a1234/Downloads/GNN/third_party/SAGPool/main.py", line 68, in test
    out = model(data)
          ^^^^^^^^^^^
  File "/Users/a1234/Downloads/GNN/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/a1234/Downloads/GNN/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/a1234/Downloads/GNN/third_party/SAGPool/networks.py", line 45, in forward
    x, edge_index, _, batch, _ = self.pool3(x, edge_index, None, batch)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/a1234/Downloads/GNN/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/a1234/Downloads/GNN/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/a1234/Downloads/GNN/third_party/SAGPool/layers.py", line 20, in forward
    perm = topk(score, self.ratio, batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/a1234/Downloads/GNN/.venv/lib/python3.12/site-packages/torch_geometric/nn/pool/select/topk.py", line 29, in topk
    num_nodes = scatter(batch.new_ones(x.size(0)), batch, reduce='sum')
                                       ^^^^^^^^^
IndexError: Dimension specified as 0 but tensor has no dimensions
